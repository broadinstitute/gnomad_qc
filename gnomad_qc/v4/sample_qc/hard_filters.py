"""Script to determine samples that fail hard filtering thresholds."""
import argparse
import logging

import hail as hl
from gnomad.resources.grch38.reference_data import telomeres_and_centromeres
from gnomad.sample_qc.filtering import compute_stratified_sample_qc
from gnomad.utils.annotations import bi_allelic_expr
from gnomad.utils.filtering import add_filters_expr, filter_to_adj, filter_to_autosomes
from gnomad.utils.slack import slack_notifications

from gnomad_qc.slack_creds import slack_token
from gnomad_qc.v4.resources.basics import (
    calling_intervals,
    get_checkpoint_path,
    get_gnomad_v4_vds,
    get_logging_path,
    gnomad_v4_testset_meta,
)
from gnomad_qc.v4.resources.meta import project_meta
from gnomad_qc.v4.resources.sample_qc import (
    contamination,
    fingerprinting_failed,
    get_sample_qc,
    hard_filtered_samples,
    hard_filtered_samples_no_sex,
    interval_coverage,
    sample_chr20_mean_dp,
    sex,
    v4_predetermined_qc,
)

logging.basicConfig(format="%(levelname)s (%(name)s %(lineno)s): %(message)s")
logger = logging.getLogger("hard_filters")
logger.setLevel(logging.INFO)


def compute_sample_qc(
    n_partitions: int = 500,
    test: bool = False,
    n_alt_alleles_strata: int = 3,
    n_alt_alleles_strata_name: str = "three",
) -> hl.Table:
    """
    Perform sample QC on the raw split matrix table using `compute_stratified_sample_qc`.

    :param n_partitions: Number of partitions to write the output sample QC HT to.
    :param test: Whether to use the gnomAD v4 test dataset. Default is to use the full dataset.
    :param n_alt_alleles_strata: Number of alternative alleles to stratify sample QC on.
        For example `n_alt_alleles_strata` = 2 will stratify 'bi-allelic' and
        'multi-allelic'. `n_alt_alleles_strata` = 3 will stratify under 3 alt alleles
        and 3 or more alt alleles. Default is 3.
    :param n_alt_alleles_strata_name: Name to use for number of alternative allele
        stratification, where strata names are 'under_{n_alt_alleles_strata_name}_alt_alleles'
        and '{n_alt_alleles_strata_name}_or_more_alt_alleles'. This is not used when
        `n_alt_alleles_strata` = 2, and instead uses 'bi-allelic' and 'multi-allelic'.
        Default is 'three'.
    :return: Table containing sample QC metrics.
    """
    logger.info("Computing sample QC")
    vds = get_gnomad_v4_vds(split=True, remove_hard_filtered_samples=False, test=test)
    vds = hl.vds.filter_chromosomes(vds, keep_autosomes=True)

    # Remove centromeres and telomeres in case they were included.
    vds = hl.vds.filter_intervals(
        vds, intervals=telomeres_and_centromeres.ht(), keep=False
    )
    if n_alt_alleles_strata < 2:
        raise ValueError("'n_alt_alleles_strata' must be greater than or equal to 2!")
    elif n_alt_alleles_strata == 2:
        strata = {
            "bi_allelic": bi_allelic_expr(vds.variant_data),
            "multi_allelic": ~bi_allelic_expr(vds.variant_data),
        }
    else:
        strata = {
            f"under_{n_alt_alleles_strata_name}_alt_alleles": vds.variant_data.n_unsplit_alleles
            <= n_alt_alleles_strata,
            f"{n_alt_alleles_strata_name}_or_more_alt_alleles": vds.variant_data.n_unsplit_alleles
            > n_alt_alleles_strata,
        }
    sample_qc_ht = compute_stratified_sample_qc(
        vds,
        strata=strata,
        tmp_ht_prefix=get_sample_qc(test=test).path[:-3],
        gt_col="GT",
    )

    return sample_qc_ht.repartition(n_partitions)


def compute_hard_filters(
    include_sex_filter: bool = False,
    max_n_singleton: float = 5000,
    max_r_het_hom_var: float = 10,
    min_bases_dp_over_1: float = 5e7,
    min_bases_dp_over_20: float = 4e7,
    max_chimera: float = 0.05,
    max_contamination_estimate: float = 0.015,
    test: bool = False,
    chr20_mean_dp_ht: hl.Table = None,
    min_cov: int = None,
    min_qc_mt_adj_callrate: float = None,
) -> hl.Table:
    """
    Apply hard filters to samples and return a Table with the filtered samples and the reason for filtering.

    If `include_sex_filter` is True, this function expects a sex inference Table generated by
    `sex_inference.py --impute-sex`.

    .. warning::
        The defaults used in this function are callset specific, these hardfilter cutoffs will need to be re-examined
        for each callset

    :param include_sex_filter: If sex inference should be used in filtering.
    :param max_n_singleton: Filtering threshold to use for the maximum number of singletons.
    :param max_r_het_hom_var: Filtering threshold to use for the maximum ratio of heterozygotes to alternate homozygotes.
    :param min_bases_dp_over_1: Filtering threshold to use for the minimum number of bases with a DP over one.
    :param min_bases_dp_over_20: Filtering threshold to use for the minimum number of bases with a DP over 20.
    :param max_chimera: Filtering threshold to use for maximum chimera (this is a proportion not a percent,
        e.g. 5% == 0.05, %5 != 5).
    :param max_contamination_estimate: Filtering threshold to use for maximum contamination estimate.
    :param test: Whether to use the gnomAD v4 test dataset. Default is to use the full dataset.
    :param chr20_mean_dp_ht: Table containing the per sample chromosome 20 mean DP.
    :param min_cov: Filtering threshold to use for chr20 coverage.
    :param min_qc_mt_adj_callrate: Filtering threshold to use for sample callrate computed on only predetermined QC
        variants (predetermined using CCDG genomes/exomes, gnomAD v3.1 genomes, and UKB exomes) after ADJ filtering.
    :return: Table of hard filtered samples.
    """
    ht = get_gnomad_v4_vds(
        remove_hard_filtered_samples=False, test=test
    ).variant_data.cols()
    ht = ht.annotate_globals(
        hard_filter_cutoffs=hl.struct(
            max_n_singleton=max_n_singleton,
            max_r_het_hom_var=max_r_het_hom_var,
            min_bases_dp_over_1=min_bases_dp_over_1,
            min_bases_dp_over_20=min_bases_dp_over_20,
            max_chimera=max_chimera,
            max_contamination_estimate=max_contamination_estimate,
        ),
    )
    if min_cov is not None:
        ht = ht.annotate_globals(
            hard_filter_cutoffs=ht.hard_filter_cutoffs.annotate(
                chr_20_dp_threshold=min_cov
            )
        )

    hard_filters = dict()
    sample_qc_metric_hard_filters = dict()

    # Flag samples failing fingerprinting.
    fp_ht = fingerprinting_failed.ht()
    hard_filters["failed_fingerprinting"] = hl.is_defined(fp_ht[ht.key])

    # Flag extreme raw bi-allelic sample QC outliers.
    bi_allelic_qc_ht = get_sample_qc("bi_allelic", test=test).ht()
    # Convert tuples to lists so we can find the index of the passed threshold.
    bi_allelic_qc_ht = bi_allelic_qc_ht.annotate(
        **{
            f"bases_dp_over_{hl.eval(bi_allelic_qc_ht.dp_bins[i])}": bi_allelic_qc_ht.bases_over_dp_threshold[
                i
            ]
            for i in range(len(bi_allelic_qc_ht.dp_bins))
        },
    )
    bi_allelic_qc_struct = bi_allelic_qc_ht[ht.key]
    sample_qc_metric_hard_filters["high_n_singleton"] = (
        bi_allelic_qc_struct.n_singleton > max_n_singleton
    )
    sample_qc_metric_hard_filters["high_r_het_hom_var"] = (
        bi_allelic_qc_struct.r_het_hom_var > max_r_het_hom_var
    )
    sample_qc_metric_hard_filters["low_bases_dp_over_1"] = (
        bi_allelic_qc_struct.bases_dp_over_1 < min_bases_dp_over_1
    )
    sample_qc_metric_hard_filters["low_bases_dp_over_20"] = (
        bi_allelic_qc_struct.bases_dp_over_20 < min_bases_dp_over_20
    )
    hard_filters["sample_qc_metrics"] = (
        sample_qc_metric_hard_filters["high_n_singleton"]
        | sample_qc_metric_hard_filters["high_r_het_hom_var"]
        | sample_qc_metric_hard_filters["low_bases_dp_over_1"]
        | sample_qc_metric_hard_filters["low_bases_dp_over_20"]
    )

    # Flag samples that fail bam metric thresholds.
    if test:
        project_meta_ht = gnomad_v4_testset_meta.ht()
        # Use the gnomAD v4 test dataset's `rand_sampling_meta` annotation to get the
        # bam metrics needed for hard filtering.
        # This annotation includes all of the metadata for the random samples
        # chosen for the test dataset.
        bam_metrics_struct = project_meta_ht[ht.key].rand_sampling_meta
        bam_metrics_struct = bam_metrics_struct.annotate(
            chimeras_rate=bam_metrics_struct.pct_chimeras
        )
        contamination_struct = hl.read_table(
            get_checkpoint_path("test_gnomad.exomes.contamination")
        )[ht.key]
    else:
        project_meta_ht = project_meta.ht()
        bam_metrics_struct = project_meta_ht[ht.key].bam_metrics
        contamination_struct = contamination.ht()[ht.key]

    hard_filters["chimera"] = bam_metrics_struct.chimeras_rate > max_chimera
    hard_filters["contamination"] = (
        contamination_struct.mean_AB_snp_biallelic > max_contamination_estimate
    )

    # Flag low-coverage samples using mean coverage on chromosome 20.
    if min_cov is not None:
        if chr20_mean_dp_ht is None:
            raise ValueError(
                "If a chromosome 20 coverage threshold is supplied, a chr20 mean DP"
                " Table must be supplied too."
            )
        hard_filters["low_coverage"] = chr20_mean_dp_ht[ht.key].chr20_mean_dp < min_cov

    if min_qc_mt_adj_callrate is not None:
        mt = v4_predetermined_qc.mt()
        num_samples = mt.count_cols()
        # Filter predetermined QC variants to only common variants (AF > 0.0001)
        # with high site callrate ( > 0.99) for ADJ genotypes.
        mt = filter_to_adj(mt)
        mt = mt.filter_rows(
            ((hl.agg.count_where(hl.is_defined(mt.GT)) / num_samples) > 0.99)
            & (
                (
                    hl.agg.sum(mt.GT.n_alt_alleles())
                    / (hl.agg.count_where(hl.is_defined(mt.GT)) * 2)
                )
                > 0.0001
            )
        )
        num_variants = mt.count_rows()
        callrate_ht = mt.annotate_cols(
            callrate_adj=hl.agg.count_where(hl.is_defined(mt.GT)) / num_variants
        ).cols()
        hard_filters["low_adj_callrate"] = (
            callrate_ht[ht.key].callrate_adj < min_qc_mt_adj_callrate
        )

    if include_sex_filter:
        sex_struct = sex.ht()[ht.key]
        # Remove samples with ambiguous sex assignments.
        hard_filters["ambiguous_sex"] = sex_struct.sex_karyotype == "ambiguous"
        hard_filters["sex_aneuploidy"] = hl.is_defined(
            sex_struct.sex_karyotype
        ) & ~hl.set(  # pylint: disable=invalid-unary-operand-type
            {"ambiguous", "XX", "XY"}
        ).contains(
            sex_struct.sex_karyotype
        )

    ht = ht.annotate(
        hard_filters=add_filters_expr(filters=hard_filters),
        sample_qc_metric_hard_filters=add_filters_expr(
            filters=sample_qc_metric_hard_filters
        ),
    )

    # Keep samples failing hard filters.
    ht = ht.filter(hl.len(ht.hard_filters) > 0)
    return ht


def main(args):
    """Determine samples that fail hard filtering thresholds."""
    hl.init(
        log="/gnomad_hard_filters.log",
        default_reference="GRCh38",
        tmp_dir="gs://gnomad-tmp-4day",
    )
    # NOTE: remove this flag when the new shuffle method is the default.
    hl._set_flags(use_new_shuffle="1")

    calling_interval_name = args.calling_interval_name
    calling_interval_padding = args.calling_interval_padding
    test = args.test
    overwrite = args.overwrite

    try:
        if args.sample_qc:
            compute_sample_qc(
                n_partitions=args.sample_qc_n_partitions,
                test=test,
                n_alt_alleles_strata=args.n_alt_alleles_strata,
                n_alt_alleles_strata_name=args.n_alt_alleles_strata_name,
            ).write(get_sample_qc(test=test).path, overwrite=overwrite)

        if args.compute_coverage:
            logger.info("Loading v4 VDS...")
            vds = get_gnomad_v4_vds(remove_hard_filtered_samples=False, test=test)

            logger.info(
                "Loading calling intervals: %s with padding of %d...",
                calling_interval_name,
                calling_interval_padding,
            )
            ht = calling_intervals(calling_interval_name, calling_interval_padding).ht()
            mt = hl.vds.interval_coverage(vds, intervals=ht)
            mt = mt.annotate_globals(
                calling_interval_name=calling_interval_name,
                calling_interval_padding=calling_interval_padding,
            )
            mt.write(
                get_checkpoint_path(
                    f"test_interval_coverage.{calling_interval_name}.pad{calling_interval_padding}",
                    mt=True,
                )
                if test
                else interval_coverage.path,
                overwrite=overwrite,
            )

        if args.compute_contamination_estimate:
            logger.info(
                "Loading v4 VDS, filtering to high-quality (DP >= %d), autosomal,"
                " bi-allelic homozygous SNVs and computing the mean of reference allele"
                " balances per sample...",
                args.contam_dp_cutoff,
            )
            mt = filter_to_autosomes(
                get_gnomad_v4_vds(
                    remove_hard_filtered_samples=False, test=test
                ).variant_data
            )
            mt = mt.filter_rows(
                (hl.len(mt.alleles) == 2) & hl.is_snp(mt.alleles[0], mt.alleles[1])
            )
            mt = mt.filter_entries(
                mt.LGT.is_hom_var() & (mt.DP >= args.contam_dp_cutoff)
            )
            mt = mt.annotate_cols(
                mean_AB_snp_biallelic=hl.agg.mean(mt.LAD[0] / (mt.LAD[0] + mt.LAD[1]))
            )
            mt = mt.cols().annotate_globals(dp_cutoff=args.contam_dp_cutoff)
            mt.write(
                get_checkpoint_path("test_gnomad.exomes.contamination")
                if test
                else contamination.path,
                overwrite=overwrite,
            )
        if args.compute_chr20_mean_dp:
            if test:
                coverage_mt = hl.read_matrix_table(
                    get_checkpoint_path(
                        f"test_interval_coverage.{calling_interval_name}.pad{calling_interval_padding}",
                        mt=True,
                    )
                )
            else:
                coverage_mt = interval_coverage.mt()

            coverage_mt = coverage_mt.filter_rows(
                coverage_mt.interval.start.contig == "chr20"
            )
            coverage_mt.select_cols(
                chr20_mean_dp=hl.agg.sum(coverage_mt.sum_dp)
                / hl.agg.sum(coverage_mt.interval_size)
            ).cols().write(
                get_checkpoint_path("test_gnomad.exomes.chr20_mean_dp")
                if test
                else sample_chr20_mean_dp.path,
                overwrite=overwrite,
            )

        if args.compute_hard_filters:
            if test:
                chr20_mean_dp_ht = hl.read_table(
                    get_checkpoint_path("test_gnomad.exomes.chr20_mean_dp")
                )
            else:
                chr20_mean_dp_ht = sample_chr20_mean_dp.ht()

            if args.include_sex_filter:
                hard_filter_path = hard_filtered_samples.path
                if test:
                    hard_filter_path = get_checkpoint_path(
                        "test_gnomad.exomes.hard_filtered_samples"
                    )
            else:
                hard_filter_path = hard_filtered_samples_no_sex.path
                if test:
                    hard_filter_path = get_checkpoint_path(
                        "test_gnomad.exomes.hard_filtered_samples_no_sex"
                    )

            ht = compute_hard_filters(
                args.include_sex_filter,
                args.max_n_singleton,
                args.max_r_het_hom_var,
                args.min_bases_dp_over_1,
                args.min_bases_dp_over_20,
                args.max_chimera,
                args.max_contamination_estimate,
                test,
                chr20_mean_dp_ht,
                args.min_cov,
                args.min_qc_mt_adj_callrate,
            )
            ht = ht.checkpoint(hard_filter_path, overwrite=overwrite)
            ht.group_by("hard_filters").aggregate(n=hl.agg.count()).show(20)
            ht.group_by("sample_qc_metric_hard_filters").aggregate(
                n=hl.agg.count()
            ).show(20)
    finally:
        logger.info("Copying log to logging bucket...")
        hl.copy_log(get_logging_path("hard_filters"))


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--overwrite",
        help="Overwrite all Matrixtables/Tables. (default: False).",
        action="store_true",
    )
    parser.add_argument(
        "--test",
        help="Use the v4 test dataset instead of the full dataset.",
        action="store_true",
    )
    parser.add_argument(
        "--sample-qc", help="Compute Hail's VDS sample QC metrics.", action="store_true"
    )
    parser.add_argument(
        "--n-alt-alleles-strata",
        help=(
            "Number of alternative alleles to stratify sample QC on. For example "
            "'n_alt_alleles_strata' = 2 will stratify 'bi-allelic' and 'multi-allelic'."
            " 'n_alt_alleles_strata' = 3 will stratify under 3 alt alleles and 3 or "
            "more alt alleles. Default is 3."
        ),
        type=int,
        default=3,
    )
    parser.add_argument(
        "--n-alt-alleles-strata-name",
        help=(
            "Name to use for number of alternative allele stratification, where strata "
            "names are 'under_{n_alt_alleles_strata_name}_alt_alleles' and "
            "'{n_alt_alleles_strata_name}_or_more_alt_alleles'. This is not used when "
            "`n_alt_alleles_strata` = 2, and instead uses 'bi-allelic' and "
            "'multi-allelic'. Default is 'three'."
        ),
        type=str,
        default="three",
    )
    parser.add_argument(
        "--sample-qc-n-partitions",
        help="Number of desired partitions for the sample QC output Table.",
        default=500,
        type=int,
    )
    parser.add_argument(
        "--compute-coverage",
        help=(
            "Compute per interval coverage metrics using Hail's vds.interval_coverage"
            " method."
        ),
        action="store_true",
    )
    parser.add_argument(
        "--compute-contamination-estimate",
        help=(
            "Compute contamination estimate as the mean of reference allele balances of"
            " high-quality (DP >= contam-dp-cutoff), autosomal, bi-allelic homozygous"
            " SNVs per sample."
        ),
        action="store_true",
    )
    parser.add_argument(
        "--contam-dp-cutoff",
        help=(
            "Minimum genotype depth to be included in contamination estimate"
            " calculation."
        ),
        type=int,
        default=10,
    )
    parser.add_argument(
        "--calling-interval-name",
        help=(
            "Name of calling intervals to use for interval coverage. One of: 'ukb',"
            " 'broad', or 'intersection'."
        ),
        type=str,
        choices=["ukb", "broad", "intersection"],
        default="intersection",
    )
    parser.add_argument(
        "--calling-interval-padding",
        help=(
            "Number of base pair padding to use on the calling intervals. One of 0 or"
            " 50 bp."
        ),
        type=int,
        choices=[0, 50],
        default=50,
    )
    parser.add_argument(
        "--compute-chr20-mean-dp",
        help=(
            "Compute per sample mean DP on chromosome 20 using interval coverage"
            " results."
        ),
        action="store_true",
    )
    parser.add_argument(
        "--compute-hard-filters",
        help=(
            "Computes samples to be hard-filtered. NOTE: Cutoffs should be determined"
            " by visual inspection of the metrics."
        ),
        action="store_true",
    )
    parser.add_argument(
        "--include-sex-filter",
        help="If sex filters should be included in hard filtering.",
        action="store_true",
    )
    parser.add_argument_group()
    hard_filter_args = parser.add_argument_group(
        "Hard-filter cutoffs", "Arguments used for hard-filter cutoffs."
    )
    hard_filter_args.add_argument(
        "--max-n-singleton",
        type=float,
        default=5000,
        help=(
            "Filtering threshold to use for the maximum number of singletons. Default"
            " is 5000."
        ),
    )
    hard_filter_args.add_argument(
        "--max-r-het-hom-var",
        type=float,
        default=10,
        help=(
            "Filtering threshold to use for the maximum ratio of heterozygotes to"
            " alternate homozygotes. Default is 10."
        ),
    )
    hard_filter_args.add_argument(
        "--min-bases-dp-over-1",
        type=float,
        help=(
            "Filtering threshold to use for the minimum number of bases with a DP over"
            " one. Default is 5e7."
        ),
        default=5e7,
    )
    hard_filter_args.add_argument(
        "--min-bases-dp-over-20",
        type=float,
        help=(
            "Filtering threshold to use for the minimum number of bases with a DP over"
            " 20. Default is 4e7."
        ),
        default=4e7,
    )
    hard_filter_args.add_argument(
        "--max-chimera",
        type=float,
        default=0.05,
        help=(
            "Filtering threshold to use for maximum chimera (this is a proportion not a"
            " percent, e.g. 5% == 0.05, %5 != 5). Default is 0.05."
        ),
    )
    hard_filter_args.add_argument(
        "--max-contamination-estimate",
        default=0.015,
        type=float,
        help=(
            "Filtering threshold to use for maximum contamination estimate (from"
            " --compute-contamination-estimate). Default is 0.015."
        ),
    )
    hard_filter_args.add_argument(
        "--min-cov",
        help=(
            "Minimum chromosome 20 coverage for inclusion when computing hard-filters."
        ),
        default=None,
        type=int,
    )
    hard_filter_args.add_argument(
        "--min-qc-mt-adj-callrate",
        help=(
            "Minimum sample callrate computed on only predetermined QC variants"
            " (predetermined using CCDG genomes/exomes, gnomAD v3.1 genomes, and UKB"
            " exomes) after ADJ filtering."
        ),
        default=None,
        type=float,
    )
    parser.add_argument(
        "--slack-channel", help="Slack channel to post results and notifications to."
    )

    args = parser.parse_args()

    if args.slack_channel:
        with slack_notifications(slack_token, args.slack_channel):
            main(args)
    else:
        main(args)
